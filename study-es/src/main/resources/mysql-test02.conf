# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
    jdbc {
        # 配置MySQL数据库连接
        jdbc_connection_string => "jdbc:mysql://127.0.0.1:3306/yunch_mall?useUnicode=true&characterEncoding=utf8&serverTimezone=UTC"
        # 用户名和密码
        jdbc_user => "root"
        jdbc_password => "root"
        # 驱动文件位置 建议：右键文件 / 安全选项 / 对象名称 里复制文件路径
        jdbc_driver_library => "E:\DevTools\logstash-7.17.3\lib\mysql\mysql-connector-j-8.0.32.jar"
        # 驱动类名
        jdbc_driver_class => "com.mysql.cj.jdbc.Driver"

        # 分页信息
        jdbc_paging_enabled => "true"
        jdbc_page_size => "5000"

        # 查询语句
        statement => "select * from pms_product"

        # 设置定时任务，定时更新同步数据; 各段分别表示：分、时、日、月、年，全部*表示每分钟更新一次
        schedule => "* * * * *"
    }
}

output {
  elasticsearch {
    hosts => ["http://127.0.0.1:9200"]
    index => "pms_product"
    # 默认文档类型
    document_type => "log"
    # 设置id
    document_id => "%{pid}"
    #user => "elastic"
    #password => "changeme"
  }
  stdout {
    codec => json_lines
  }
}
